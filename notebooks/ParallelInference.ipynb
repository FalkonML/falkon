{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from falkon import Falkon, kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parallel = 15\n",
    "N = 19000\n",
    "M = 2000\n",
    "D = 1024\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(num_parallel, N, D)\n",
    "W = torch.randn(num_parallel, M, D)\n",
    "alpha = torch.randn(num_parallel, M, 1)\n",
    "if cuda:\n",
    "    X, W, alpha = X.cuda(), W.cuda(), alpha.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal kernels (falkon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = kernels.GaussianKernel(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 ms ± 1.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds = torch.empty(num_parallel, N, 1, device=X.device)\n",
    "for i in range(num_parallel):\n",
    "    preds[i] = kernel.mmv(X[i], W[i], alpha[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0015, 0.001, 1.5)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0015, 1/1000, 22.5/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal kernels (in-core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from falkon.la_helpers.cuda_la_helpers import square_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_times = []\n",
    "mm_times = []\n",
    "mulexp_times = []\n",
    "# @torch.jit.script\n",
    "def squared_euclidean_distance(x1, x2):\n",
    "    t_0 = time.time()\n",
    "    x1_norm = torch.norm(x1, p=2, dim=-1, keepdim=True).pow_(2)  # N x 1\n",
    "    x2_norm = torch.norm(x2, p=2, dim=-1, keepdim=True).pow_(2)  # M x 1\n",
    "#     x1_norm = square_norm(x1, dim=-1, keepdim=True)\n",
    "#     x2_norm = square_norm(x2, dim=-1, keepdim=True)\n",
    "    torch.cuda.synchronize()\n",
    "    t_1 = time.time()\n",
    "    res = torch.addmm(x2_norm.transpose(-2, -1), x1, x2.transpose(-2, -1), alpha=-2).add_(x1_norm)\n",
    "    torch.cuda.synchronize()\n",
    "    t_2 = time.time()\n",
    "    res = res.clamp_min_(1e-30)\n",
    "    norm_times.append(t_1-t_0)\n",
    "    mm_times.append(t_2-t_1)\n",
    "    torch.cuda.synchronize()\n",
    "    return res\n",
    "# @torch.jit.script\n",
    "def full_rbf_kernel(X1, X2, sigma):\n",
    "    pairwise_dists = squared_euclidean_distance(X1 / sigma, X2 / sigma)\n",
    "    t_3 = time.time()\n",
    "    pairwise_dists.mul_(-0.5).exp_()\n",
    "    torch.cuda.synchronize()\n",
    "    t_4 = time.time()\n",
    "    mulexp_times.append(t_4-t_3)\n",
    "    return pairwise_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 ms ± 8.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds = torch.empty(num_parallel, N, 1, device=X.device)\n",
    "for i in range(num_parallel):\n",
    "    preds[i] = full_rbf_kernel(X[i], W[i], torch.tensor(1.0)) @ alpha[i]\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.79ms - MM: 6.99ms - MulExp: 1.36ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Norm: %.2fms - MM: %.2fms - MulExp: %.2fms\" % (\n",
    "    np.mean(norm_times) * 1000, np.mean(mm_times) * 1000, np.mean(mulexp_times) * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.97ms - MM: 8.02ms - MulExp: 1.50ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Norm: %.2fms - MM: %.2fms - MulExp: %.2fms\" % (\n",
    "    np.mean(norm_times) * 1000, np.mean(mm_times) * 1000, np.mean(mulexp_times) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch kernel (in-core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def batch_sqeuc(x1, x2):\n",
    "    x1_norm = torch.norm(x1, p=2, dim=-1, keepdim=True).pow_(2)  # B x N x 1\n",
    "    x2_norm = torch.norm(x2, p=2, dim=-1, keepdim=True).pow_(2)  # B x M x 1\n",
    "    # B x 1 x M + (B x N x 1  @  B x 1 x M)\n",
    "    res = torch.baddbmm(x2_norm.transpose(-2, -1), x1, x2.transpose(-2, -1), alpha=-2).add_(x1_norm)\n",
    "    res = res.clamp_min_(1e-30)\n",
    "    return res\n",
    "@torch.jit.script\n",
    "def batch_rbf_kernel(X1, X2, sigma):\n",
    "    pairwise_dists = batch_sqeuc(X1 / sigma, X2 / sigma)\n",
    "    return pairwise_dists.mul_(-0.5).exp_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = batch_rbf_kernel(X, W, torch.tensor(1.0)) @ alpha\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.1 ms ± 9.09 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds = batch_rbf_kernel(X, W, torch.tensor(1.0)) @ alpha\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch kernel (keops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeops.torch import Genred\n",
    "from pykeops.torch import LazyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = f'Exp(IntInv(-2) * Sum(Square(Var(0,{D},0)/s - Var(1,{D},1)/s))) * Var(2,1,1)'\n",
    "aliases = [\n",
    "    f'Var(0,{D},0)',\n",
    "    f'Var(1,{D},1)',\n",
    "    'Var(2,1,1)',\n",
    "    's = Pm(1)',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = Genred(formula, aliases, reduction_op='Sum', axis=1, dtype='float32',\n",
    "            rec_multVar_highdim=None, enable_chunks=True)\n",
    "variables = [X, W, alpha, torch.tensor([1.0], device=X.device).reshape(-1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.7 ms ± 36.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preds2 = fn(*variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch kernel (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from falkon.mmv_ops import mmv_cuda\n",
    "from falkon.kernels import GaussianKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GaussianKernel(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.12 ms ± 65.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = mmv_cuda.fmmv_cuda(X, W, alpha, kernel)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
