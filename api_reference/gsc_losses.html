<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>falkon.gsc_losses &mdash; falkon 0.8.2 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="falkon.preconditioner" href="preconditioner.html" />
    <link rel="prev" title="falkon.options" href="options.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            falkon
          </a>
              <div class="version">
                0.8.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#supported-platforms">Supported Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#pytorch-and-cuda">PyTorch and CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../install.html#intel-mkl">Intel MKL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing">Installing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing-the-installation">Testing the installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#development">Development</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#passing-options">Passing Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#more-examples">More Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_regression_tutorial.html">Falkon Regression Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Pre-process-the-data">Pre-process the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Create-the-Falkon-model">Create the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Training-the-model">Training the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Evaluating-model-performance">Evaluating model performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html">Introducing Logistic Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-the-Falkon-model">Define the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-Logistic-Falkon-model">Define Logistic Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Train-both-models">Train both models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html#Plot-predictions">Plot predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_cv.html">Hyperparameter Tuning with Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Search-for-the-optimal-parameters">Search for the optimal parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/falkon_cv.html#Evaluating-the-model">Evaluating the model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Plot-grid-search-results">Plot grid-search results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/custom_kernels.html">Implementing A Custom Kernel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Setup-a-simple-problem-for-testing">Setup a simple problem for testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Basic-Kernel-Implementation">Basic Kernel Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-basic-kernel">Test the basic kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Differentiable-Kernel">Differentiable Kernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-differentiable-kernel">Test the differentiable kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Adding-KeOps-Support">Adding KeOps Support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-KeOps-kernel">Test the KeOps kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Supporting-Sparse-Data">Supporting Sparse Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Testing-sparse-support">Testing sparse support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/hyperopt.html">Automatic Hyperparameter Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Hyperparameter-Optimization">Hyperparameter Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_mnist.html">MNIST Classification with Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Download-the-MNIST-dataset-&amp;-load-it-in-memory">Download the MNIST dataset &amp; load it in memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Run-Falkon">Run Falkon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">falkon.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="models.html#falkon">Falkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.Falkon"><code class="docutils literal notranslate"><span class="pre">Falkon</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="models.html#logisticfalkon">LogisticFalkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.LogisticFalkon"><code class="docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="models.html#incorefalkon">InCoreFalkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.InCoreFalkon"><code class="docutils literal notranslate"><span class="pre">InCoreFalkon</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kernels.html">falkon.kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#kernel">Kernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel"><code class="docutils literal notranslate"><span class="pre">Kernel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#diffkernel">DiffKernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.diff_kernel.DiffKernel"><code class="docutils literal notranslate"><span class="pre">DiffKernel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#keopskernelmixin">KeopsKernelMixin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.keops_helpers.KeopsKernelMixin"><code class="docutils literal notranslate"><span class="pre">KeopsKernelMixin</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#radial-kernels">Radial kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#gaussian-kernel">Gaussian kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#laplacian-kernel">Laplacian kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#matern-kernel">Matern kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#dot-product-kernels">Dot-Product kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#polynomial-kernel">Polynomial kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#linear-kernel">Linear kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#sigmoid-kernel">Sigmoid kernel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="options.html">falkon.options</a><ul>
<li class="toctree-l3"><a class="reference internal" href="options.html#falkonoptions">FalkonOptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="options.html#falkon.options.FalkonOptions"><code class="docutils literal notranslate"><span class="pre">FalkonOptions</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">falkon.gsc_losses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loss">Loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#falkon.gsc_losses.Loss"><code class="docutils literal notranslate"><span class="pre">Loss</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#logistic-loss">Logistic loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#falkon.gsc_losses.LogisticLoss"><code class="docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#weighted-binary-cross-entropy-loss">Weighted binary cross entropy loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#falkon.gsc_losses.WeightedCrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">WeightedCrossEntropyLoss</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="preconditioner.html">falkon.preconditioner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#preconditioner">Preconditioner</a><ul>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#falkon.preconditioner.preconditioner.Preconditioner"><code class="docutils literal notranslate"><span class="pre">Preconditioner</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#cholesky-preconditioners">Cholesky preconditioners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#falkonpreconditioner">FalkonPreconditioner</a></li>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#logisticpreconditioner">LogisticPreconditioner</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">falkon.optim</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#optimizer">Optimizer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#falkon.optim.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#conjugate-gradient-methods">Conjugate gradient methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#conjugategradient">ConjugateGradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#falkonconjugategradient">FalkonConjugateGradient</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="outofcore.html">falkon.ooc_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-cholesky">gpu_cholesky</a><ul>
<li class="toctree-l4"><a class="reference internal" href="outofcore.html#falkon.ooc_ops.gpu_cholesky"><code class="docutils literal notranslate"><span class="pre">gpu_cholesky()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-lauum">gpu_lauum</a><ul>
<li class="toctree-l4"><a class="reference internal" href="outofcore.html#falkon.ooc_ops.gpu_lauum"><code class="docutils literal notranslate"><span class="pre">gpu_lauum()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mmv_ops.html">falkon.mmv_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#run-keops-mmv">run_keops_mmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.keops.run_keops_mmv"><code class="docutils literal notranslate"><span class="pre">run_keops_mmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm">fmm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmm.fmm"><code class="docutils literal notranslate"><span class="pre">fmm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv">fmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.fmmv"><code class="docutils literal notranslate"><span class="pre">fmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv">fdmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.fdmmv"><code class="docutils literal notranslate"><span class="pre">fdmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fmmv">incore_fmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv_incore.incore_fmmv"><code class="docutils literal notranslate"><span class="pre">incore_fmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fdmmv">incore_fdmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv_incore.incore_fdmmv"><code class="docutils literal notranslate"><span class="pre">incore_fdmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#low-level-functions">Low-level functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmm.sparse_mm_run_thread"><code class="docutils literal notranslate"><span class="pre">sparse_mm_run_thread()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.sparse_mmv_run_thread"><code class="docutils literal notranslate"><span class="pre">sparse_mmv_run_thread()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sparse.html">falkon.sparse</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparsetensor">SparseTensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_tensor.SparseTensor"><code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_tensor.SparseType"><code class="docutils literal notranslate"><span class="pre">SparseType</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparse-operations">Sparse operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_matmul"><code class="docutils literal notranslate"><span class="pre">sparse_matmul()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_square_norm"><code class="docutils literal notranslate"><span class="pre">sparse_square_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_norm"><code class="docutils literal notranslate"><span class="pre">sparse_norm()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="center_selector.html">falkon.center_selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#centerselector">CenterSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.CenterSelector"><code class="docutils literal notranslate"><span class="pre">CenterSelector</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#uniformselector">UniformSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.UniformSelector"><code class="docutils literal notranslate"><span class="pre">UniformSelector</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#fixedselector">FixedSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.FixedSelector"><code class="docutils literal notranslate"><span class="pre">FixedSelector</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hopt.html">falkon.hopt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hopt.html#objectives">Objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#falkon.hopt.objectives.objectives.HyperoptObjective"><code class="docutils literal notranslate"><span class="pre">HyperoptObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#nystrom-complexity-regularization">Nystrom Complexity Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#stochastic-nystrom-computational-regularization">Stochastic Nystrom Computational Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#complexity-regularization">Complexity Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#generalized-cross-validation">Generalized Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#hold-out-cross-validation">Hold Out Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#leave-one-out-cross-validation">Leave One Out Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#sgpr">SGPR</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">falkon</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">API Reference</a></li>
      <li class="breadcrumb-item active">falkon.gsc_losses</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_reference/gsc_losses.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-falkon">
<span id="falkon-gsc-losses"></span><h1>falkon.gsc_losses<a class="headerlink" href="#module-falkon" title="Permalink to this heading"></a></h1>
<section id="loss">
<h2>Loss<a class="headerlink" href="#loss" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></span><span class="sig-name descname"><span class="pre">Loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">FalkonOptions</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.Loss" title="Permalink to this definition"></a></dt>
<dd><p>Abstract generalized self-concordant loss function class.</p>
<p>Such loss functions must be three times differentiable; but for the logistic Falkon algorithm
only the first two derivatives are used.
Subclasses must implement the <a class="reference internal" href="#falkon.gsc_losses.Loss.__call__" title="falkon.gsc_losses.Loss.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a> method which calculates the loss function
given two input vectors (the inputs could also be matrices e.g. for the softmax loss),
the <a class="reference internal" href="#falkon.gsc_losses.Loss.df" title="falkon.gsc_losses.Loss.df"><code class="xref py py-meth docutils literal notranslate"><span class="pre">df()</span></code></a> method which calculates the first derivative of the function and <a class="reference internal" href="#falkon.gsc_losses.Loss.ddf" title="falkon.gsc_losses.Loss.ddf"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ddf()</span></code></a>
which calculates the second derivative.</p>
<p>Additionally, this class provides two methods (<a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_grad" title="falkon.gsc_losses.Loss.knmp_grad"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_grad()</span></code></a> and <a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_hess" title="falkon.gsc_losses.Loss.knmp_hess"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_hess()</span></code></a>) which
calculate kernel-vector products using the loss derivatives for vectors. These functions are
specific to the logistic Falkon algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – A descriptive name for the loss function (e.g. “logistic”, “softmax”)</p></li>
<li><p><strong>kernel</strong> – The kernel function used for training a LogFalkon model</p></li>
<li><p><strong>opt</strong> – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#falkon.gsc_losses.LogisticLoss" title="falkon.gsc_losses.LogisticLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a></dt><dd><p>a concrete implementation of this class for the logistic loss.</p>
</dd>
<dt><a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">falkon.models.LogisticFalkon</span></code></a></dt><dd><p>the logistic Falkon model which uses GSC losses.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss.__call__">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Abstract method. Should return the loss for predicting <cite>y2</cite> with true labels <cite>y1</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The loss calculated for the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss.ddf">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ddf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.ddf" title="Permalink to this definition"></a></dt>
<dd><p>Abstract method. Should return the second derivative of the loss wrt <cite>y2</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels. The derivative
should be computed with respect to this tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The second derivative of the loss with respect to <cite>y2</cite>. It will be a tensor of the
same shape as the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss.df">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.df" title="Permalink to this definition"></a></dt>
<dd><p>Abstract method. Should return the derivative of the loss wrt <cite>y2</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels. The derivative
should be computed with respect to this tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The derivative of the loss with respect to <cite>y2</cite>. It will be a tensor of the same shape
as the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss.knmp_grad">
<span class="sig-name descname"><span class="pre">knmp_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Xc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">FalkonOptions</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.knmp_grad" title="Permalink to this definition"></a></dt>
<dd><p>Computes a kernel vector product where the vector is the first derivative of this loss</p>
<p>Given kernel function <span class="math notranslate nohighlight">\(K\)</span>, the loss represented by this class <span class="math notranslate nohighlight">\(\mathcal{l}\)</span>,
number of samples <span class="math notranslate nohighlight">\(n\)</span>, this function follows equation</p>
<div class="math notranslate nohighlight">
\[\dfrac{1}{n} K(X_c, X) &#64; (\mathcal{l}'(Y, K(X, X_c) &#64; u))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Data matrix of shape (n x d) with <cite>n</cite> samples in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Xc</strong> (<em>torch.Tensor</em>) – Center matrix of shape (m x d) with <cite>m</cite> centers in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – Label matrix of shape (n x t) with <cite>n</cite> samples. Depending on the loss, the labels may or may not
have more than one dimension.</p></li>
<li><p><strong>u</strong> (<em>torch.Tensor</em>) – A vector (or matrix if the labels are multi-dimensional) of weights of shape (m x t).
The product <cite>K(X, Xc) &#64; u</cite>, where <cite>K</cite> is the kernel associated to this loss, should
produce label predictions.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a><em> or </em><em>None</em>) – Options to be passed to the mmv function for the kernel associated to this loss.
Options passed as an argument take precedence over the options used to build this
class instance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>grad_mul</strong> (<em>torch.Tensor</em>) – A tensor of shape (m x 1) coming from the multiplication of the kernel matrix
<cite>K(Xc, X)</cite> and the loss calculated on predictions with weights <cite>u</cite>.
The formula followed is: <cite>(1/n) * K(Xc, X) &#64; df(Y, K(X, Xc) &#64; u)</cite>.</p></li>
<li><p><strong>func_val</strong> (<em>torch.Tensor</em>) – A tensor of shape (n x t) of predictions obtained with weights <cite>u</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.Loss.knmp_hess">
<span class="sig-name descname"><span class="pre">knmp_hess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Xc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">FalkonOptions</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.knmp_hess" title="Permalink to this definition"></a></dt>
<dd><p>Compute a kernel-vector product with a rescaling with the second derivative</p>
<p>Given kernel function <span class="math notranslate nohighlight">\(K\)</span>, the loss represented by this class <span class="math notranslate nohighlight">\(\mathcal{l}\)</span>,
number of samples <span class="math notranslate nohighlight">\(n\)</span>, this function follows equation</p>
<div class="math notranslate nohighlight">
\[\dfrac{1}{n} K(X_c, X) &#64; (\mathcal{l}''(Y, f) * K(X, X_c) &#64; u)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Data matrix of shape (n x d) with <cite>n</cite> samples in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Xc</strong> (<em>torch.Tensor</em>) – Center matrix of shape (m x d) with <cite>m</cite> centers in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – Label matrix of shape (n x t) with <cite>n</cite> samples. Depending on the loss, the labels may
or may not have more than one dimension.</p></li>
<li><p><strong>f</strong> (<em>torch.Tensor</em>) – Tensor of shape (n x t) of predictions. Typically this will be the second output of
the <a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_grad" title="falkon.gsc_losses.Loss.knmp_grad"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_grad()</span></code></a> method.</p></li>
<li><p><strong>u</strong> (<em>torch.Tensor</em>) – A vector (or matrix if the labels are multi-dimensional) of weights of shape (m x t).
The product <cite>K(X, Xc) &#64; u</cite>, where <cite>K</cite> is the kernel associated to this loss, should
produce label predictions.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a><em> or </em><em>None</em>) – Options to be passed to the mmv function for the kernel associated to this loss.
Options passed as an argument take precedence over the options used to build this
class instance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>A tensor of shape (m x t), the output of the computation.</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="logistic-loss">
<h2>Logistic loss<a class="headerlink" href="#logistic-loss" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="falkon.gsc_losses.LogisticLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></span><span class="sig-name descname"><span class="pre">LogisticLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">FalkonOptions</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper for the logistic loss, to be used in conjunction with the <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> estimator.</p>
<p>Usage of this loss assumes a binary classification problem with labels -1 and +1. For different
choices of labels, see <a class="reference internal" href="#falkon.gsc_losses.WeightedCrossEntropyLoss" title="falkon.gsc_losses.WeightedCrossEntropyLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">WeightedCrossEntropyLoss</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><em>falkon.kernels.kernel.Kernel</em></a>) – The kernel function used for training a <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> model</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a>) – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">GaussianKernel</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_loss</span> <span class="o">=</span> <span class="n">LogisticLoss</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">LogisticFalkon</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">log_loss</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.LogisticLoss.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Compute the logistic loss between two 1-dimensional tensors</p>
<p>The formula used is <span class="math notranslate nohighlight">\(\log(1 + \exp(-y_1 * y_2))\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>loss</em> – The logistic loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.LogisticLoss.ddf">
<span class="sig-name descname"><span class="pre">ddf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.ddf" title="Permalink to this definition"></a></dt>
<dd><p>Compute the second derivative of the logistic loss with respect to <cite>y2</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[y_1^2 \dfrac{1}{1 + \exp(-y_1 * y_2)} \dfrac{1}{1 + \exp(y_1 * y_2)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dd_loss</em> – The second derivative of the logistic loss, calculated between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.LogisticLoss.df">
<span class="sig-name descname"><span class="pre">df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.df" title="Permalink to this definition"></a></dt>
<dd><p>Compute the derivative of the logistic loss with respect to <cite>y2</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-y_1}{1 + \exp(y_1 * y_2)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>d_loss</em> – The derivative of the logistic loss, calculated between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="weighted-binary-cross-entropy-loss">
<h2>Weighted binary cross entropy loss<a class="headerlink" href="#weighted-binary-cross-entropy-loss" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="falkon.gsc_losses.WeightedCrossEntropyLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></span><span class="sig-name descname"><span class="pre">WeightedCrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">FalkonOptions</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper for the weighted binary cross-entropy loss, to be used with the <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> estimator.</p>
<p>Using this loss assumes a binary classification problem with labels 0 and +1. Additionally,
this loss allows to place a different weight to samples belonging to one of the two classes
(see the <cite>neg_weight</cite> parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><em>falkon.kernels.kernel.Kernel</em></a>) – The kernel function used for training a <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> model</p></li>
<li><p><strong>neg_weight</strong> (<em>float</em>) – The weight to be assigned to samples belonging to the negative (0-labeled) class.
By setting <cite>neg_weight</cite> to 1, the classes are equally weighted and this loss is
equivalent to the <a class="reference internal" href="#falkon.gsc_losses.LogisticLoss" title="falkon.gsc_losses.LogisticLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a> loss, but with a different
choice of labels.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a>) – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">GaussianKernel</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wce_loss</span> <span class="o">=</span> <span class="n">WeightedCrossEntropyLoss</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">LogisticFalkon</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">wce_loss</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.WeightedCrossEntropyLoss.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Compute the weighted BCE loss between two 1-dimensional tensors</p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\mathrm{true} * \log(1 + e^{-\mathrm{pred}}) + w * (1 - \mathrm{true}) * \log(1 + e^{\mathrm{pred}})\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D, with values 0 or 1.</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D. These are “logits” so need not be scaled before
hand.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>loss</em> – The weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.WeightedCrossEntropyLoss.ddf">
<span class="sig-name descname"><span class="pre">ddf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.ddf" title="Permalink to this definition"></a></dt>
<dd><p>Compute the second derivative of the weighted BCE loss with respect to <cite>pred</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-(\mathrm{true} * (w - 1) - w) * e^{\mathrm{pred}}}{(e^{\mathrm{pred}} + 1)^2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dd_loss</em> – The second derivative of the weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="falkon.gsc_losses.WeightedCrossEntropyLoss.df">
<span class="sig-name descname"><span class="pre">df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.df" title="Permalink to this definition"></a></dt>
<dd><p>Compute the derivative of the weighted BCE loss with respect to <cite>pred</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-(w * \mathrm{true} - w) * e^{\mathrm{pred}} - \mathrm{true}}{e^{\mathrm{pred}} + 1}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>d_loss</em> – The derivative of the weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="options.html" class="btn btn-neutral float-left" title="falkon.options" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="preconditioner.html" class="btn btn-neutral float-right" title="falkon.preconditioner" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Giacomo Meanti, Alessandro Rudi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>