

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>falkon.gsc_losses &mdash; falkon 0.6.3 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="falkon.preconditioner" href="preconditioner.html" />
    <link rel="prev" title="falkon.options" href="options.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> falkon
          

          
          </a>

          
            
            
              <div class="version">
                0.6.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#supported-platforms">Supported Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#pytorch-and-cuda">PyTorch and CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../install.html#intel-mkl">Intel MKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../install.html#keops">KeOps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing">Installing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing-the-installation">Testing the installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#passing-options">Passing Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#more-examples">More Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/simple_regression.html">Falkon Regression Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Pre-process-the-data">Pre-process the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Create-the-Falkon-model">Create the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Training-the-model">Training the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/simple_regression.html#Evaluating-model-performance">Evaluating model performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html">Introducing Logistic Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-the-Falkon-model">Define the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-Logistic-Falkon-model">Define Logistic Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Train-both-models">Train both models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html#Plot-predictions">Plot predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/hyperparameter_tuning.html">Hyperparameter Tuning with Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Search-for-the-optimal-parameters">Search for the optimal parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Evaluating-the-model">Evaluating the model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperparameter_tuning.html#Plot-grid-search-results">Plot grid-search results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/performance_tuning.html">Training on the GPU</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">falkon.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="models.html#falkon">Falkon</a></li>
<li class="toctree-l3"><a class="reference internal" href="models.html#logisticfalkon">LogisticFalkon</a></li>
<li class="toctree-l3"><a class="reference internal" href="models.html#incorefalkon">InCoreFalkon</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kernels.html">falkon.kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#kernel">Kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#radial-kernels">Radial kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#gaussian-kernel">Gaussian kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#laplacian-kernel">Laplacian kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#dot-product-kernels">Dot-Product kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#polynomial-kernel">Polynomial kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#linear-kernel">Linear kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#sigmoid-kernel">Sigmoid kernel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="options.html">falkon.options</a><ul>
<li class="toctree-l3"><a class="reference internal" href="options.html#falkonoptions">FalkonOptions</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">falkon.gsc_losses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loss">Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logistic-loss">Logistic loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#weighted-binary-cross-entropy-loss">Weighted binary cross entropy loss</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="preconditioner.html">falkon.preconditioner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#preconditioner">Preconditioner</a></li>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#cholesky-preconditioners">Cholesky preconditioners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#falkonpreconditioner">FalkonPreconditioner</a></li>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#logisticpreconditioner">LogisticPreconditioner</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">falkon.optim</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#optimizer">Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#conjugate-gradient-methods">Conjugate gradient methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#conjugategradient">ConjugateGradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#falkonconjugategradient">FalkonConjugateGradient</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="outofcore.html">falkon.ooc_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-cholesky">gpu_cholesky</a></li>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-lauum">gpu_lauum</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mmv_ops.html">falkon.mmv_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#run-keops-mmv">run_keops_mmv</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm-cpu">fmm_cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm-cpu-sparse">fmm_cpu_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm-cuda">fmm_cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm-cuda-sparse">fmm_cuda_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv-cpu">fmmv_cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv-cpu-sparse">fmmv_cpu_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv-cpu">fdmmv_cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv-cpu-sparse">fdmmv_cpu_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv-cuda">fmmv_cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv-cuda-sparse">fmmv_cuda_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv-cuda">fdmmv_cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv-cuda-sparse">fdmmv_cuda_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fmmv">incore_fmmv</a></li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fdmmv">incore_fdmmv</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sparse.html">falkon.sparse</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparsetensor">SparseTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparse-operations">Sparse operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="center_selector.html">falkon.center_selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#centerselector">CenterSelector</a></li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#uniformselector">UniformSelector</a></li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#fixedselector">FixedSelector</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">falkon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">API Reference</a> &raquo;</li>
        
      <li>falkon.gsc_losses</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api_reference/gsc_losses.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="module-falkon">
<span id="falkon-gsc-losses"></span><h1>falkon.gsc_losses<a class="headerlink" href="#module-falkon" title="Permalink to this headline">¶</a></h1>
<section id="loss">
<h2>Loss<a class="headerlink" href="#loss" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="falkon.gsc_losses.Loss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></code><code class="sig-name descname"><span class="pre">Loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">falkon.kernels.kernel.Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">falkon.options.FalkonOptions</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract generalized self-concordant loss function class.</p>
<p>Such loss functions must be three times differentiable; but for the logistic Falkon algorithm
only the first two derivatives are used.
Subclasses must implement the <a class="reference internal" href="#falkon.gsc_losses.Loss.__call__" title="falkon.gsc_losses.Loss.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a> method which calculates the loss function
given two input vectors (the inputs could also be matrices e.g. for the softmax loss),
the <a class="reference internal" href="#falkon.gsc_losses.Loss.df" title="falkon.gsc_losses.Loss.df"><code class="xref py py-meth docutils literal notranslate"><span class="pre">df()</span></code></a> method which calculates the first derivative of the function and <a class="reference internal" href="#falkon.gsc_losses.Loss.ddf" title="falkon.gsc_losses.Loss.ddf"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ddf()</span></code></a>
which calculates the second derivative.</p>
<p>Additionally, this class provides two methods (<a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_grad" title="falkon.gsc_losses.Loss.knmp_grad"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_grad()</span></code></a> and <a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_hess" title="falkon.gsc_losses.Loss.knmp_hess"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_hess()</span></code></a>) which
calculate kernel-vector products using the loss derivatives for vectors. These functions are
specific to the logistic Falkon algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – A descriptive name for the loss function (e.g. “logistic”, “softmax”)</p></li>
<li><p><strong>kernel</strong> – The kernel function used for training a LogFalkon model</p></li>
<li><p><strong>opt</strong> – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#falkon.gsc_losses.LogisticLoss" title="falkon.gsc_losses.LogisticLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a></dt><dd><p>a concrete implementation of this class for the logistic loss.</p>
</dd>
<dt><a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">falkon.models.LogisticFalkon</span></code></a></dt><dd><p>the logistic Falkon model which uses GSC losses.</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt id="falkon.gsc_losses.Loss.__call__">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">__call__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.Loss.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Should return the loss for predicting <cite>y2</cite> with true labels <cite>y1</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The loss calculated for the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.Loss.ddf">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">ddf</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.Loss.ddf" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Should return the second derivative of the loss wrt <cite>y2</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels. The derivative
should be computed with respect to this tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The second derivative of the loss with respect to <cite>y2</cite>. It will be a tensor of the
same shape as the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.Loss.df">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">df</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.Loss.df" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Should return the derivative of the loss wrt <cite>y2</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>torch.Tensor</em>) – One of the two inputs to the loss. This should be interpreted as the <cite>true</cite> labels.</p></li>
<li><p><strong>y2</strong> (<em>torch.Tensor</em>) – The other loss input. Should be interpreted as the predicted labels. The derivative
should be computed with respect to this tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The derivative of the loss with respect to <cite>y2</cite>. It will be a tensor of the same shape
as the two inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.Loss.knmp_grad">
<code class="sig-name descname"><span class="pre">knmp_grad</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Xc</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">falkon.options.FalkonOptions</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#falkon.gsc_losses.Loss.knmp_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a kernel vector product where the vector is the first derivative of this loss</p>
<p>Given kernel function <span class="math notranslate nohighlight">\(K\)</span>, the loss represented by this class <span class="math notranslate nohighlight">\(\mathcal{l}\)</span>,
number of samples <span class="math notranslate nohighlight">\(n\)</span>, this function follows equation</p>
<div class="math notranslate nohighlight">
\[\dfrac{1}{n} K(X_c, X) &#64; (\mathcal{l}'(Y, K(X, X_c) &#64; u))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Data matrix of shape (n x d) with <cite>n</cite> samples in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Xc</strong> (<em>torch.Tensor</em>) – Center matrix of shape (m x d) with <cite>m</cite> centers in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – Label matrix of shape (n x t) with <cite>n</cite> samples. Depending on the loss, the labels may or may not
have more than one dimension.</p></li>
<li><p><strong>u</strong> (<em>torch.Tensor</em>) – A vector (or matrix if the labels are multi-dimensional) of weights of shape (m x t).
The product <cite>K(X, Xc) &#64; u</cite>, where <cite>K</cite> is the kernel associated to this loss, should
produce label predictions.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a><em> or </em><em>None</em>) – Options to be passed to the mmv function for the kernel associated to this loss.
Options passed as an argument take precedence over the options used to build this
class instance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>grad_mul</strong> (<em>torch.Tensor</em>) – A tensor of shape (m x 1) coming from the multiplication of the kernel matrix
<cite>K(Xc, X)</cite> and the loss calculated on predictions with weights <cite>u</cite>.
The formula followed is: <cite>(1/n) * K(Xc, X) &#64; df(Y, K(X, Xc) &#64; u)</cite>.</p></li>
<li><p><strong>func_val</strong> (<em>torch.Tensor</em>) – A tensor of shape (n x t) of predictions obtained with weights <cite>u</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.Loss.knmp_hess">
<code class="sig-name descname"><span class="pre">knmp_hess</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Xc</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">falkon.options.FalkonOptions</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.Loss.knmp_hess" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a kernel-vector product with a rescaling with the second derivative</p>
<p>Given kernel function <span class="math notranslate nohighlight">\(K\)</span>, the loss represented by this class <span class="math notranslate nohighlight">\(\mathcal{l}\)</span>,
number of samples <span class="math notranslate nohighlight">\(n\)</span>, this function follows equation</p>
<div class="math notranslate nohighlight">
\[\dfrac{1}{n} K(X_c, X) &#64; (\mathcal{l}''(Y, f) * K(X, X_c) &#64; u)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Data matrix of shape (n x d) with <cite>n</cite> samples in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Xc</strong> (<em>torch.Tensor</em>) – Center matrix of shape (m x d) with <cite>m</cite> centers in <cite>d</cite> dimensions.</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – Label matrix of shape (n x t) with <cite>n</cite> samples. Depending on the loss, the labels may
or may not have more than one dimension.</p></li>
<li><p><strong>f</strong> (<em>torch.Tensor</em>) – Tensor of shape (n x t) of predictions. Typically this will be the second output of
the <a class="reference internal" href="#falkon.gsc_losses.Loss.knmp_grad" title="falkon.gsc_losses.Loss.knmp_grad"><code class="xref py py-meth docutils literal notranslate"><span class="pre">knmp_grad()</span></code></a> method.</p></li>
<li><p><strong>u</strong> (<em>torch.Tensor</em>) – A vector (or matrix if the labels are multi-dimensional) of weights of shape (m x t).
The product <cite>K(X, Xc) &#64; u</cite>, where <cite>K</cite> is the kernel associated to this loss, should
produce label predictions.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a><em> or </em><em>None</em>) – Options to be passed to the mmv function for the kernel associated to this loss.
Options passed as an argument take precedence over the options used to build this
class instance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>A tensor of shape (m x t), the output of the computation.</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="logistic-loss">
<h2>Logistic loss<a class="headerlink" href="#logistic-loss" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="falkon.gsc_losses.LogisticLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></code><code class="sig-name descname"><span class="pre">LogisticLoss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">falkon.kernels.kernel.Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">falkon.options.FalkonOptions</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for the logistic loss, to be used in conjunction with the <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> estimator.</p>
<p>Usage of this loss assumes a binary classification problem with labels -1 and +1. For different
choices of labels, see <a class="reference internal" href="#falkon.gsc_losses.WeightedCrossEntropyLoss" title="falkon.gsc_losses.WeightedCrossEntropyLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">WeightedCrossEntropyLoss</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><em>falkon.kernels.kernel.Kernel</em></a>) – The kernel function used for training a <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> model</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a>) – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">GaussianKernel</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_loss</span> <span class="o">=</span> <span class="n">LogisticLoss</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">LogisticFalkon</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">log_loss</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="falkon.gsc_losses.LogisticLoss.__call__">
<code class="sig-name descname"><span class="pre">__call__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the logistic loss between two 1-dimensional tensors</p>
<p>The formula used is <span class="math notranslate nohighlight">\(\log(1 + \exp(-y_1 * y_2))\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>loss</em> – The logistic loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.LogisticLoss.ddf">
<code class="sig-name descname"><span class="pre">ddf</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.ddf" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the second derivative of the logistic loss with respect to <cite>y2</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[y_1^2 \dfrac{1}{1 + \exp(-y_1 * y_2)} \dfrac{1}{1 + \exp(y_1 * y_2)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>dd_loss</em> – The second derivative of the logistic loss, calculated between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.LogisticLoss.df">
<code class="sig-name descname"><span class="pre">df</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.LogisticLoss.df" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the derivative of the logistic loss with respect to <cite>y2</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-y_1}{1 + \exp(y_1 * y_2)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> – The first input tensor. Must be 1D</p></li>
<li><p><strong>y2</strong> – The second input tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>d_loss</em> – The derivative of the logistic loss, calculated between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="weighted-binary-cross-entropy-loss">
<h2>Weighted binary cross entropy loss<a class="headerlink" href="#weighted-binary-cross-entropy-loss" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="falkon.gsc_losses.WeightedCrossEntropyLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">falkon.gsc_losses.</span></code><code class="sig-name descname"><span class="pre">WeightedCrossEntropyLoss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><span class="pre">falkon.kernels.kernel.Kernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_weight</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><span class="pre">falkon.options.FalkonOptions</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for the weighted binary cross-entropy loss, to be used with the <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> estimator.</p>
<p>Using this loss assumes a binary classification problem with labels 0 and +1. Additionally,
this loss allows to place a different weight to samples belonging to one of the two classes
(see the <cite>neg_weight</cite> parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel" title="falkon.kernels.kernel.Kernel"><em>falkon.kernels.kernel.Kernel</em></a>) – The kernel function used for training a <a class="reference internal" href="models.html#falkon.models.LogisticFalkon" title="falkon.models.LogisticFalkon"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a> model</p></li>
<li><p><strong>neg_weight</strong> (<em>float</em>) – The weight to be assigned to samples belonging to the negative (0-labeled) class.
By setting <cite>neg_weight</cite> to 1, the classes are equally weighted and this loss is
equivalent to the <a class="reference internal" href="#falkon.gsc_losses.LogisticLoss" title="falkon.gsc_losses.LogisticLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a> loss, but with a different
choice of labels.</p></li>
<li><p><strong>opt</strong> (<a class="reference internal" href="options.html#falkon.options.FalkonOptions" title="falkon.options.FalkonOptions"><em>FalkonOptions</em></a>) – Falkon options container. Will be passed to the kernel when computing kernel-vector
products.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">GaussianKernel</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wce_loss</span> <span class="o">=</span> <span class="n">WeightedCrossEntropyLoss</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">falkon</span><span class="o">.</span><span class="n">LogisticFalkon</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">wce_loss</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="falkon.gsc_losses.WeightedCrossEntropyLoss.__call__">
<code class="sig-name descname"><span class="pre">__call__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the weighted BCE loss between two 1-dimensional tensors</p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\mathrm{true} * \log(1 + e^{-\mathrm{pred}}) + w * (1 - \mathrm{true}) * \log(1 + e^{\mathrm{pred}})\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D, with values 0 or 1.</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D. These are “logits” so need not be scaled before
hand.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>loss</em> – The weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.WeightedCrossEntropyLoss.ddf">
<code class="sig-name descname"><span class="pre">ddf</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.ddf" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the second derivative of the weighted BCE loss with respect to <cite>pred</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-(\mathrm{true} * (w - 1) - w) * e^{\mathrm{pred}}}{(e^{\mathrm{pred}} + 1)^2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>dd_loss</em> – The second derivative of the weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="falkon.gsc_losses.WeightedCrossEntropyLoss.df">
<code class="sig-name descname"><span class="pre">df</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="headerlink" href="#falkon.gsc_losses.WeightedCrossEntropyLoss.df" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the derivative of the weighted BCE loss with respect to <cite>pred</cite></p>
<p>The formula used is</p>
<div class="math notranslate nohighlight">
\[\dfrac{-(w * \mathrm{true} - w) * e^{\mathrm{pred}} - \mathrm{true}}{e^{\mathrm{pred}} + 1}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true</strong> – The label tensor. Must be 1D</p></li>
<li><p><strong>pred</strong> – The prediction tensor. Must be 1D</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>d_loss</em> – The derivative of the weighted BCE loss between the two input vectors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="preconditioner.html" class="btn btn-neutral float-right" title="falkon.preconditioner" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="options.html" class="btn btn-neutral float-left" title="falkon.options" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Giacomo Meanti.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>