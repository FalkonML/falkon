

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>falkon.options &mdash; falkon 0.9.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=1bc1ca25"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="falkon.gsc_losses" href="gsc_losses.html" />
    <link rel="prev" title="falkon.kernels" href="kernels.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            falkon
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#supported-platforms">Supported Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install.html#pytorch-and-cuda">PyTorch and CUDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../install.html#intel-mkl">Intel MKL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#installing">Installing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#testing-the-installation">Testing the installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#development">Development</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#passing-options">Passing Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="../get_started.html#more-examples">More Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_regression_tutorial.html">Falkon Regression Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Pre-process-the-data">Pre-process the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Create-the-Falkon-model">Create the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Training-the-model">Training the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_regression_tutorial.html#Evaluating-model-performance">Evaluating model performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html">Introducing Logistic Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-the-Falkon-model">Define the Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Define-Logistic-Falkon-model">Define Logistic Falkon model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Train-both-models">Train both models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/logistic_falkon.html#Testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/logistic_falkon.html#Plot-predictions">Plot predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_cv.html">Hyperparameter Tuning with Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Search-for-the-optimal-parameters">Search for the optimal parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/falkon_cv.html#Evaluating-the-model">Evaluating the model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_cv.html#Plot-grid-search-results">Plot grid-search results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/custom_kernels.html">Implementing A Custom Kernel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Setup-a-simple-problem-for-testing">Setup a simple problem for testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Basic-Kernel-Implementation">Basic Kernel Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-basic-kernel">Test the basic kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Differentiable-Kernel">Differentiable Kernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-differentiable-kernel">Test the differentiable kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Adding-KeOps-Support">Adding KeOps Support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Test-the-KeOps-kernel">Test the KeOps kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/custom_kernels.html#Supporting-Sparse-Data">Supporting Sparse Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/custom_kernels.html#Testing-sparse-support">Testing sparse support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/hyperopt.html">Automatic Hyperparameter Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Split-into-training-and-test-sets">Split into training and test sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/hyperopt.html#Hyperparameter-Optimization">Hyperparameter Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/falkon_mnist.html">MNIST Classification with Falkon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Download-the-MNIST-dataset-&amp;-load-it-in-memory">Download the MNIST dataset &amp; load it in memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Data-Preprocessing">Data Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/falkon_mnist.html#Run-Falkon">Run Falkon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">falkon.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="models.html#falkon">Falkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.Falkon"><code class="docutils literal notranslate"><span class="pre">Falkon</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="models.html#logisticfalkon">LogisticFalkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.LogisticFalkon"><code class="docutils literal notranslate"><span class="pre">LogisticFalkon</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="models.html#incorefalkon">InCoreFalkon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="models.html#falkon.models.InCoreFalkon"><code class="docutils literal notranslate"><span class="pre">InCoreFalkon</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kernels.html">falkon.kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#kernel">Kernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.kernel.Kernel"><code class="docutils literal notranslate"><span class="pre">Kernel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#diffkernel">DiffKernel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.diff_kernel.DiffKernel"><code class="docutils literal notranslate"><span class="pre">DiffKernel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#keopskernelmixin">KeopsKernelMixin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#falkon.kernels.keops_helpers.KeopsKernelMixin"><code class="docutils literal notranslate"><span class="pre">KeopsKernelMixin</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#radial-kernels">Radial kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#gaussian-kernel">Gaussian kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#laplacian-kernel">Laplacian kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#matern-kernel">Matern kernel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kernels.html#dot-product-kernels">Dot-Product kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#polynomial-kernel">Polynomial kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#linear-kernel">Linear kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="kernels.html#sigmoid-kernel">Sigmoid kernel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">falkon.options</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#falkonoptions">FalkonOptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#falkon.options.FalkonOptions"><code class="docutils literal notranslate"><span class="pre">FalkonOptions</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gsc_losses.html">falkon.gsc_losses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gsc_losses.html#loss">Loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gsc_losses.html#falkon.gsc_losses.Loss"><code class="docutils literal notranslate"><span class="pre">Loss</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gsc_losses.html#logistic-loss">Logistic loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gsc_losses.html#falkon.gsc_losses.LogisticLoss"><code class="docutils literal notranslate"><span class="pre">LogisticLoss</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gsc_losses.html#weighted-binary-cross-entropy-loss">Weighted binary cross entropy loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="gsc_losses.html#falkon.gsc_losses.WeightedCrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">WeightedCrossEntropyLoss</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="preconditioner.html">falkon.preconditioner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#preconditioner">Preconditioner</a><ul>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#falkon.preconditioner.preconditioner.Preconditioner"><code class="docutils literal notranslate"><span class="pre">Preconditioner</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="preconditioner.html#cholesky-preconditioners">Cholesky preconditioners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#falkonpreconditioner">FalkonPreconditioner</a></li>
<li class="toctree-l4"><a class="reference internal" href="preconditioner.html#logisticpreconditioner">LogisticPreconditioner</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">falkon.optim</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#optimizer">Optimizer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#falkon.optim.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#conjugate-gradient-methods">Conjugate gradient methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#conjugategradient">ConjugateGradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#falkonconjugategradient">FalkonConjugateGradient</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="outofcore.html">falkon.ooc_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-cholesky">gpu_cholesky</a><ul>
<li class="toctree-l4"><a class="reference internal" href="outofcore.html#falkon.ooc_ops.gpu_cholesky"><code class="docutils literal notranslate"><span class="pre">gpu_cholesky()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="outofcore.html#gpu-lauum">gpu_lauum</a><ul>
<li class="toctree-l4"><a class="reference internal" href="outofcore.html#falkon.ooc_ops.gpu_lauum"><code class="docutils literal notranslate"><span class="pre">gpu_lauum()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mmv_ops.html">falkon.mmv_ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#run-keops-mmv">run_keops_mmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.keops.run_keops_mmv"><code class="docutils literal notranslate"><span class="pre">run_keops_mmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmm">fmm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmm.fmm"><code class="docutils literal notranslate"><span class="pre">fmm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fmmv">fmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.fmmv"><code class="docutils literal notranslate"><span class="pre">fmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#fdmmv">fdmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.fdmmv"><code class="docutils literal notranslate"><span class="pre">fdmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fmmv">incore_fmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv_incore.incore_fmmv"><code class="docutils literal notranslate"><span class="pre">incore_fmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#incore-fdmmv">incore_fdmmv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv_incore.incore_fdmmv"><code class="docutils literal notranslate"><span class="pre">incore_fdmmv()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mmv_ops.html#low-level-functions">Low-level functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmm.sparse_mm_run_thread"><code class="docutils literal notranslate"><span class="pre">sparse_mm_run_thread()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="mmv_ops.html#falkon.mmv_ops.fmmv.sparse_mmv_run_thread"><code class="docutils literal notranslate"><span class="pre">sparse_mmv_run_thread()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sparse.html">falkon.sparse</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparsetensor">SparseTensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_tensor.SparseTensor"><code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_tensor.SparseType"><code class="docutils literal notranslate"><span class="pre">SparseType</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sparse.html#sparse-operations">Sparse operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_matmul"><code class="docutils literal notranslate"><span class="pre">sparse_matmul()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_square_norm"><code class="docutils literal notranslate"><span class="pre">sparse_square_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html#falkon.sparse.sparse_norm"><code class="docutils literal notranslate"><span class="pre">sparse_norm()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="center_selector.html">falkon.center_selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#centerselector">CenterSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.CenterSelector"><code class="docutils literal notranslate"><span class="pre">CenterSelector</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#uniformselector">UniformSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.UniformSelector"><code class="docutils literal notranslate"><span class="pre">UniformSelector</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="center_selector.html#fixedselector">FixedSelector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="center_selector.html#falkon.center_selection.FixedSelector"><code class="docutils literal notranslate"><span class="pre">FixedSelector</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hopt.html">falkon.hopt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hopt.html#objectives">Objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#falkon.hopt.objectives.objectives.HyperoptObjective"><code class="docutils literal notranslate"><span class="pre">HyperoptObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#nystrom-complexity-regularization">Nystrom Complexity Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#stochastic-nystrom-computational-regularization">Stochastic Nystrom Computational Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#complexity-regularization">Complexity Regularization</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#generalized-cross-validation">Generalized Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#hold-out-cross-validation">Hold Out Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#leave-one-out-cross-validation">Leave One Out Cross Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hopt.html#sgpr">SGPR</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">falkon</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">API Reference</a></li>
      <li class="breadcrumb-item active">falkon.options</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_reference/options.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-falkon.options">
<span id="falkon-options"></span><span id="api-options"></span><h1>falkon.options<a class="headerlink" href="#module-falkon.options" title="Permalink to this heading"></a></h1>
<section id="falkonoptions">
<h2>FalkonOptions<a class="headerlink" href="#falkonoptions" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="falkon.options.FalkonOptions">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">falkon.options.</span></span><span class="sig-name descname"><span class="pre">FalkonOptions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keops_acc_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keops_sum_scheme</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keops_active</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keops_memory_slack</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chol_force_in_core</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chol_force_ooc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chol_par_blk_multiplier</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pc_epsilon_32</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pc_epsilon_64</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-13</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cpu_preconditioner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_epsilon_32</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_epsilon_64</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_tolerance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_full_gradient_every</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cg_differential_convergence</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_gpu_mem</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cpu_mem</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_arch_speed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_single_kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cuda_pc_size_32</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cuda_pc_size_64</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cuda_iter_size_32</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">300000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cuda_iter_size_64</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">900000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">never_store_kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_kernel_d_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fmm_streams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_slack</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#falkon.options.FalkonOptions" title="Permalink to this definition"></a></dt>
<dd><p>Global options for Falkon.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>debug</strong> (<em>bool</em>) – <cite>default False</cite> - When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the estimators will print extensive debugging information.
Set it if you want to dig deeper.</p></li>
<li><p><strong>use_cpu</strong> (<em>bool</em>) – <cite>default False</cite> - When set to <code class="docutils literal notranslate"><span class="pre">True</span></code> forces Falkon not to use the GPU. If this option is not set,
and no GPU is available, Falkon will issue a warning.</p></li>
<li><p><strong>max_gpu_mem</strong> (<em>float</em>) – The maximum GPU memory (in bytes) that Falkon may use. If not set, Falkon will
use all available memory.</p></li>
<li><p><strong>max_cpu_mem</strong> (<em>float</em>) – The maximum CPU RAM (in bytes) that Falkon may use. If not set, Falkon will
use all available memory. This option is not a strict bound (due to the nature
of memory management in Python).</p></li>
<li><p><strong>compute_arch_speed</strong> (<em>bool</em>) – <cite>default False</cite> - When running Falkon on a machine with multiple GPUs which have a range of different
performance characteristics, setting this option to <cite>True</cite> may help subdivide the
workload better: the performance of each accelerator will be evaluated on startup,
then the faster devices will receive more work than the slower ones.
If this is not the case, do not set this option since evaluating accelerator performance
increases startup times.</p></li>
<li><p><strong>no_single_kernel</strong> (<em>bool</em>) – <cite>default True</cite> - Whether the kernel should always be evaluated in double precision.
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, kernel evaluations will be faster but less precise (note that this
referes only to calculations involving the full kernel matrix, not to kernel-vector
products).</p></li>
<li><p><strong>min_cuda_pc_size_32</strong> (<em>int</em>) – <cite>default 10000</cite> - If M (the number of Nystroem centers) is lower than <code class="docutils literal notranslate"><span class="pre">min_cuda_pc_size_32</span></code>, falkon will
run the preconditioner on the CPU. Otherwise, if CUDA is available, falkon will try
to run the preconditioner on the GPU. This setting is valid for data in single
(float32) precision.
Along with the <code class="docutils literal notranslate"><span class="pre">min_cuda_iter_size_32</span></code> setting, this determines a cutoff for running
Falkon on the CPU or the GPU. Such cutoff is useful since for small-data problems
running on the CPU may be faster than running on the GPU. If your data is close to the
cutoff, it may be worth experimenting with running on the CPU and on the GPU to check
which side is faster. This will depend on the exact hardware.</p></li>
<li><p><strong>min_cuda_pc_size_64</strong> (<em>int</em>) – <cite>default 30000</cite> - If M (the number of Nystroem centers) is lower than <code class="docutils literal notranslate"><span class="pre">min_cuda_pc_size_64</span></code>,
falkon will run the preconditioner on the CPU. Otherwise, if CUDA is available, falkon will try
to run the preconditioner on the GPU. This setting is valid for data in double
(float64) precision.
Along with the <code class="docutils literal notranslate"><span class="pre">min_cuda_iter_size_64</span></code> setting, this determines a cutoff for running
Falkon on the CPU or the GPU. Such cutoff is useful since for small-data problems
running on the CPU may be faster than running on the GPU. If your data is close to the
cutoff, it may be worth experimenting with running on the CPU and on the GPU to check
which side is faster. This will depend on the exact hardware.</p></li>
<li><p><strong>min_cuda_iter_size_32</strong> (<em>int</em>) – <cite>default 300_000_000</cite> - If the data size (measured as the product of M, and the dimensions of X) is lower than
<code class="docutils literal notranslate"><span class="pre">min_cuda_iter_size_32</span></code>, falkon will run the conjugate gradient iterations on the CPU.
For example, with the default setting, the CPU-GPU threshold is set at a dataset
with 10k points, 10 dimensions, and 3k Nystroem centers. A larger dataset, or the use
of more centers, will cause the conjugate gradient iterations to run on the GPU.
This setting is valid for data in single (float32) precision.</p></li>
<li><p><strong>min_cuda_iter_size_64</strong> (<em>int</em>) – <cite>default 900_000_000</cite> - If the data size (measured as the product of M, and the dimensions of X) is lower than
<code class="docutils literal notranslate"><span class="pre">min_cuda_iter_size_64</span></code>, falkon will run the conjugate gradient iterations on the CPU.
For example, with the default setting, the CPU-GPU threshold is set at a dataset
with 30k points, 10 dimensions, and 3k Nystroem centers. A larger dataset, or the use
of more centers, will cause the conjugate gradient iterations to run on the GPU.
This setting is valid for data in double (float64) precision.</p></li>
<li><p><strong>never_store_kernel</strong> (<em>bool</em>) – <cite>default False</cite> - If set to True, the kernel between the data and the Nystroem centers will not
be stored - even if there is sufficient RAM to do so. Setting this option to
True may (in case there would be enough RAM to store the kernel), increase the
training time for Falkon since the K_NM matrix must be recomputed at every
conjugate gradient iteration.</p></li>
<li><p><strong>store_kernel_d_threshold</strong> (<em>int</em>) – <cite>default 1200</cite> - The minimum data-dimensionality (<cite>d</cite>) for which to consider whether to store
the full Knm kernel matrix (between the data-points and the Nystrom centers). The final decision
on whether the matrix is stored or not is based on the amount of memory available.
Storing the Knm matrix may greatly reduce training and inference times, especially if <cite>d</cite> is
large, or for kernels which are costly to compute.</p></li>
<li><p><strong>num_fmm_streams</strong> (<em>int</em>) – <cite>default 2</cite> - The number of CUDA streams to use for evaluating kernels when CUDA is available.
This number should be increased from its default value when the number of Nystroem centers is
higher than around 5000.</p></li>
<li><p><strong>memory_slack</strong> (<em>float</em>) – <cite>default 0.9</cite> - Controls the amount of slack in GPU memory when calculating the size of matrix
splits for kernel-vector multiplications. This can be reduced if out-of-memory errors occur
on the GPU.</p></li>
<li><p><strong>keops_acc_dtype</strong> (<em>str</em>) – <cite>default “auto”</cite> - A string describing the accumulator data-type for KeOps.
For more information refer to the
<a class="reference external" href="https://www.kernel-operations.io/keops/python/api/pytorch/Genred_torch.html?highlight=genred#pykeops.torch.Genred">KeOps documentation</a></p></li>
<li><p><strong>keops_sum_scheme</strong> (<em>str</em>) – <cite>default “auto”</cite> - Accumulation scheme for KeOps.
For more information refer to the <a class="reference external" href="https://www.kernel-operations.io/keops/python/api/pytorch/Genred_torch.html?highlight=genred#pykeops.torch.Genred">KeOps documentation</a></p></li>
<li><p><strong>keops_active</strong> (<em>str</em>) – <cite>default “auto”</cite> - Whether to use or not to use KeOps. Three settings are allowed, specified by strings:
‘auto’ (the default setting) means that KeOps will be used if it is installed correctly,
‘no’ means keops will not be used, nor will it be imported, and ‘force’ means that if KeOps is
not installed an error will be raised.</p></li>
<li><p><strong>keops_memory_slack</strong> (<em>float</em>) – <cite>default 0.7</cite> - Controls the amount of slack used when calculating the matrix splits for KeOps.
Since memory usage estimation for KeOps is hard, you may need to reduce this value if running
out-of-GPU-memory when using KeOps. Typically this only occurs for large datasets.</p></li>
<li><p><strong>cg_epsilon_32</strong> (<em>float</em>) – <cite>default 1e-7</cite> - Small added epsilon to prevent divide-by-zero errors in the conjugate
gradient algorithm. Used for single precision data-types</p></li>
<li><p><strong>cg_epsilon_64</strong> (<em>float</em>) – <cite>default 1e-15</cite> - Small added epsilon to prevent divide-by-zero errors in the conjugate
gradient algorithm. Used for double precision data-types</p></li>
<li><p><strong>cg_tolerance</strong> (<em>float</em>) – <cite>default 1e-7</cite> - Maximum change in model parameters between iterations. If less change than
<code class="docutils literal notranslate"><span class="pre">cg_tolerance</span></code> is detected, then we regard the optimization as converged.</p></li>
<li><p><strong>cg_full_gradient_every</strong> (<em>int</em>) – <cite>default 10</cite> - How often to calculate the full gradient in the conjugate gradient algorithm.
Full-gradient iterations take roughly twice the time as normal iterations, but they reset
the error introduced by the other iterations.</p></li>
<li><p><strong>cg_differential_convergence</strong> (<em>bool</em>) – <cite>default False</cite> - Differential convergence refers to a procedure relevant to the conjugate
gradient optimizer, and only applies when multiple right-hand side vectors are used (e.g.
in multi-class classification, or in hyperparameter optimization with the stochastic objective).
If this flag is set, whenever the convergence criterion is met for single right-hand-sides,
they are removed from the optimization procedure. If it is not set, all vectors must have
converged for the optimization to stop. It is especially useful for hyperparameter optimization.</p></li>
<li><p><strong>pc_epsilon_32</strong> (<em>float</em>) – <cite>default 1e-5</cite> - Epsilon used to increase the diagonal dominance of a matrix before its
Cholesky decomposition (for single-precision data types).</p></li>
<li><p><strong>pc_epsilon_64</strong> (<em>float</em>) – <cite>default 1e-13</cite> - Epsilon used to increase the diagonal dominance of a matrix before its
Cholesky decomposition (for double-precision data types).</p></li>
<li><p><strong>cpu_preconditioner</strong> (<em>bool</em>) – <cite>default False</cite> - Whether the preconditioner should be computed on the CPU. This setting
overrides the <code class="xref py py-attr docutils literal notranslate"><span class="pre">FalkonOptions.use_cpu</span></code> option.</p></li>
<li><p><strong>chol_force_in_core</strong> (<em>bool</em>) – <cite>default False</cite> - Whether to force in-core execution of the Cholesky decomposition. This will
not work with matrices bigger than GPU memory.</p></li>
<li><p><strong>chol_force_ooc</strong> (<em>bool</em>) – <cite>default False</cite> - Whether to force out-of-core (parallel) execution for the POTRF algorithm,
even on matrices which fit in-GPU-core.</p></li>
<li><p><strong>chol_par_blk_multiplier</strong> () – <cite>default 2</cite> - Minimum number of tiles per-GPU in the out-of-core, GPU-parallel POTRF algorithm.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="kernels.html" class="btn btn-neutral float-left" title="falkon.kernels" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="gsc_losses.html" class="btn btn-neutral float-right" title="falkon.gsc_losses" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Giacomo Meanti, Alessandro Rudi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>